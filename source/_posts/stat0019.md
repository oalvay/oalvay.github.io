---
title: Summary Note - Decision and Risk  
date: 2020-02-17 15:30:00
tags:
- Notes
---

I recently came up with an idea. Insteading of summarizing lectures by hands, how about using markdown and post on blog?

<!-- more -->

Conditioning on the known value of the data y, and using Bayes’ theorem, yields the ***posterior density***:

$$p(\theta|\mathbf{y}) = \frac{p(\theta, \mathbf{y})}{p(\mathbf{y})} = \frac{p(\theta)p(\mathbf{y}|\theta)}{p(\mathbf{y})}$$

where:  

+ $$p(\theta∣\mathbf{y})$$ - is the ***posterior density*** for θ and represents the uncertainty about θ after conditioning on the data y.
+ $$p(\theta)$$ - is the ***prior density*** for θ that expresses our uncertainty about the values of θ before taking into account sample information (i.e. observed data).
+ $$p(\mathbf{y}|\theta)$$  - when regarded as a function of θ, for fixed y, is the ***likelihood function***.
+ $$p(\mathbf{y})$$ - is the marginal density of the data y, normally written as:

$$p(\mathbf{y}) = \underbrace{\sum_{\theta} p(\theta)p(\mathbf{y}|\theta)}_{\mbox{discrete} \ \theta} = \underbrace{\int_{\theta} p(\theta)p(\mathbf{y}|\theta) \ d\theta}_{\mbox{continuous} \ \theta}$$

Or, by omitting the normalizing constant $$p(\mathbf{y})$$,we have the ***unnormalized posterior density***:

$$\begin{align*}
p(\theta∣\mathbf{y}) 
& \propto p(\theta) \cdot p(\mathbf{y}|\theta) \\
& \propto \text{prior pdf ⋅ likelihood function}
\end{align*}$$ 

The parameters that controls prior distrition are called ***hyperparameters***.

---
In a Bayesian analysis, we first need to represent our prior beliefs about θ, by constructing a probability distribution p(θ) which encapsulates our beliefs.  

p(θ) will not be the same for different people as they may have different knowledge about what proportion of coins are biased.

In some cases, p(θ) may be based on subjective judgement, while in others it may be based on objective evidence. This is the essence of Bayesian statistics - probabilities express degrees of beliefs.

# Decision Theory

## Bayesian decision theory

\- concerned with making decisions that perform best, based on the information we have about the un- knowns.

### Basic Elements of a Decision Problem

- &nbsp;$$\Theta$$ is the ***parameter space*** which consists of all possible “states of nature” or “states of the world” $$\theta$$, only one of which will occur. The “true” state of nature $$\theta$$ is unknown.

- &nbsp;$$A = (a_1,a_2,...,a_k)$$ is the ***action space***, which is the set of all pos- sible actions available, $$a \in A$$ .

- &nbsp;$$\Omega$$ contains all possible realisations $$y \in \Omega$$ of a random variable $$Y$$ which belongs to the family $$\{ f(y; \theta)∣ \theta \in \Theta \} $$

- &nbsp;$$L(\theta, a)$$ is a ***loss function*** that has the domain $$Θ \times A = \{ (θ, a)∣ θ ∈ Θ \ \text{and} \ a ∈ A \}$$ and codomain $$\mathbb{R}$$. That is, a loss function maps each combination of states of the world θ and action a onto a numerical loss, R. For technical convenience, $$L(θ, a) ≥ −K > −∞$$

#### Loss Function

The loss function $$L(\theta,a)$$ is a core element of decision making which represents the loss incurred if we choose action a when the true state of the world is $$\theta$$ (usually unknown).

The losses corresponding to each action and state of world θ can be represented by a loss matrix:

 &nbsp;|$$\theta = 0$$&nbsp;|$$\theta = 1$$ &nbsp;
---|---|---
$$a_1$$&nbsp;|0|10
$$a_0$$&nbsp;|1|0
which fully specifies the loss function $$L(\theta,a)$$ for all values of θ and a.
